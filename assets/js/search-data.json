{
  
    
        "post0": {
            "title": "Analyzing Crime in Chicago",
            "content": "Abstract . This report’s intent is to give an initial overview of the recorded incidents of crime in the city of Chicago from 2001 to 2021. The data is provided in a publicly available dataset by the Chicago Police Department. The report is an initial overview about the total numbers of crimes, their types, and development over time. All charts in this report have been created with Apache Superset. . It is the first report in a series that is based on the data of this dataset and its purpose is to lay the groundwork for further analysis. . . Introduction | Data | Analysis | Crime in General | Trends in Crime | Conclusion | . { &quot;tags&quot;: [ &quot;hide_input&quot;, ] } from IPython.display import Image from pathlib import Path . Introduction . The following report will give an overview on the development of crime counts in the city of Chicago from 2001 to 2021. This analysis includes includes a broad overview on the total number of crimes in the dataset, their development over time and the distribution of the types of crime. We will also have a look on the trend of recorded number of crimes overall and in detail. . Data . This analysis is based on the reported incidents of crime in the City of Chicago. The dataset starts in the year of 2001 and is updated daily. It only excludes the most recent seven days. The data is provided by the Chicago Police Department itself. This dataset records among others the date and time of the incident, detailed information on the location, the crime type and description, if an arrest was made and if it was a domestic crime. . This dataset is publicly available on the Chicago Data Portal: • https://data.cityofchicago .org/Public-Safety/Crimes-2001-to-Present/ijzp-q8t2 . The accuracy, completeness, timeliness or correct sequencing of the provided records is not guaranteed. So comparisons of over time created with it should be taken with a grain of salt. In addition, older records are subject to change. . Analysis . Crime in General . At first let us take a look on the total amount of crimes committed and what their primary types are. From 2001 to 2021 there have been a total of 7.47 million recorded crimes by the Chicago Police Department. Overall these crimes split into 36 different types. The most common crimes are theft, battery, criminal damage and cases involving narcotics. These four types alone amount to 4.5 million of the 7.47 million records overall, which is 61 %. . path = Path.cwd().joinpath(&#39;images&#39;).joinpath(&#39;r#1&#39;).joinpath (&#39;01.jpg&#39;) Image(filename=path) . Next, we will investigate the development of the crime count per year. Overall there has been a steady decline in the number of recorded crimes since 2001. In the beginning there we roughly 486,000 counted crimes compared to the 206,000 in 2021. The decline in felonies comes although the population has increased by 2 % from 2010 to 2020. It rose from 2.696 million to 2.746 million according to the united status census bureau[1]. . ￼ [1] https://www.census.gov/quickfacts/fact/table/chicagocityillinois/POP010210#POP010210 . path = Path.cwd().joinpath(&#39;images&#39;).joinpath(&#39;r#1&#39;).joinpath (&#39;02.jpg&#39;) Image(filename=path) . Another important distinction to look at is the the percentage of domestic crimes overall. 1.02 million of the total crimes counted were flagged as domestic. This results in a share of 13.66 % of all committed crimes. Further analysis shows that the share per year steadily increases as the absolute number of domestic crimes stagnates. The amount of non-domestic crime continues to decrease since 2001. . path = Path.cwd().joinpath(&#39;images&#39;).joinpath(&#39;r#1&#39;).joinpath (&#39;03.jpg&#39;) Image(filename=path) . Trends in Crime . In this second part we take a look at trends in the numbers of recorded crime. The next graph shows the development of the total numbers of recorded crimes in a 10 year period from 2011 to 2021. In 2011 there were 351,935 cases compared to 205,742 in 2021. Therefore we can see a decrease of nearly 42 % in recorded incidents. . path = Path.cwd().joinpath(&#39;images&#39;).joinpath(&#39;r#1&#39;).joinpath (&#39;04.jpg&#39;) Image(filename=path) . Next, we created an development overview of the 10 most counted crime types over a 20 year period. In general, most of the types have seen a steady decrease, which is also in accordance to the decrease of overall crime. Theft and Battery have stayed the two most recorded felonies in this entire timespan. . While theft and battery have seen a steady decrease, deceptive practice has seen an increase. Crimes that involve narcotics have reached an all-time low. In 2001 these crimes were the fourth most committed overall. Now they are the least committed out of this ranking. Records involving Criminal Damage have somewhat bottomed out and not been decreasing that much. . path = Path.cwd().joinpath(&#39;images&#39;).joinpath(&#39;r#1&#39;).joinpath (&#39;05.jpg&#39;) Image(filename=path) . In this last part we compare the development of domestic and non-domestic violence. In 2001 12 % of all committed crimes where domestic, compared to 22 % in 2021. While the amount of non-domestic crime reduced from 427,000 to 161,000, domestic crime only shrank to 44,700 from 58,700. Also, there is a notable increase in domestic crime by 4,800 from 2020 to 2021. This could be influenced by changes in the daily life caused by the COVID-19 pandemic. Aside from that, we can see a steady decrease in number of recorded incidents. . path = Path.cwd().joinpath(&#39;images&#39;).joinpath(&#39;r#1&#39;).joinpath (&#39;06.jpg&#39;) Image(filename=path) . Conclusion . In general, there was a continuous decrease in the number of recorded crimes since 2001 by 57.6 percent. This comes although the population in Chicago has risen. Despite this decrease took place, in these 20 years domestic crime has been relatively stable and not nearly decreased that much. Hence the non-domestic crime has seen a much larger decline. Theft, Battery and criminal damage have been the three most committed crimes since the beginning. Theft was the most, battery the 2nd and criminal damage the 3rd most recorded type. Crimes involving narcotics have seen the largest decrease. From being the fourth most recorded crime in 2001 to dropping down to the tenth most recorded. . In the following reports we will take a further look at the areas in which crimes are committed and their development over time. And in addition I will take a deep dive into crime types and their development. .",
            "url": "https://elydora.github.io/DataScienceBlog/data_science/visualization/2022/05/01/chicago-r-1.html",
            "relUrl": "/data_science/visualization/2022/05/01/chicago-r-1.html",
            "date": " • May 1, 2022"
        }
        
    
  
    
        ,"post1": {
            "title": "Python Short Reference",
            "content": "Complex Data Types . Copying and References . import copy first_str = &quot;Will&quot; second_str = copy.copy(first_str) print(first_str) print(second_str) . Will Will . names = [&quot;Jan&quot;, &quot;Felix&quot;, &quot;Ralph&quot;] second_names = names second_names[1] = &quot;Maria&quot; print(names) print(second_names) . [&#39;Jan&#39;, &#39;Maria&#39;, &#39;Ralph&#39;] [&#39;Jan&#39;, &#39;Maria&#39;, &#39;Ralph&#39;] . third_names = copy.copy(names) third_names[0] = &quot;Julia&quot; print(names) print(third_names) . [&#39;Jan&#39;, &#39;Maria&#39;, &#39;Ralph&#39;] [&#39;Julia&#39;, &#39;Maria&#39;, &#39;Ralph&#39;] . Dictionaries and Sets . Dictionaries . bike_owners = {&quot;James&quot;:&quot;Ducati Monster 1200&quot;, &quot;Jacob&quot;:&quot;Ducati Scrambler 1100&quot;} # printing an element bike_owners[&quot;Jacob&quot;] . int_dict = {1:45, 2:55, 3:65} int_dict[1] . 45 . int_dict.keys() . dict_keys([1, 2, 3]) . mixed_dict = {False: &quot;Daniel&quot;, &quot;Aria&quot;:[1,2,3], &quot;Jacob&quot;:True} mixed_dict . {False: &#39;Daniel&#39;, &#39;Aria&#39;: [1, 2, 3], &#39;Jacob&#39;: True} . del int_dict[3] int_dict . {1: 45, 2: 55} . fruits = { &quot;Banana&quot;:[50,60,75,99], &quot;Apple&quot;:[48,86,47,25], &quot;Strawberries&quot;:[70,80,60,65] } print(fruits[&quot;Banana&quot;]) print(fruits[&quot;Banana&quot;][3]) fruits[&quot;Banana&quot;][3]=50 print(fruits[&quot;Banana&quot;][3]) . [50, 60, 75, 99] 99 50 . print(len(fruits)) # sorting a dict print(sorted(fruits)) # return key value pairs print(fruits.items()) . 3 [&#39;Apple&#39;, &#39;Banana&#39;, &#39;Strawberries&#39;] . dict_items([(&#39;Banana&#39;, [50, 60, 75, 50]), (&#39;Apple&#39;, [48, 86, 47, 25]), (&#39;Strawberries&#39;, [70, 80, 60, 65])]) . Sets . set_string = {&quot;Emma&quot;, &quot;Olivia&quot;, &quot;Ava&quot;, &quot;Mia&quot;} print(set_string) # no intrinsic ordering empty_set = set() mixed_set = {&quot;Emmma&quot;, 5, 1.5, True,(1,2,3,4)} student_set = {&quot;Emma&quot;, &quot;Marc&quot;, &quot;Janine&quot;, &quot;Emma&quot;} print(student_set) # duplicates are eliminated . student_set.add(&quot;Felix&quot;) print(len(student_set)) print(max(student_set)) student_set.remove(&quot;Felix&quot;) . number1={1,2,3,4,5} number2={4,5,6,7,8} number3={7,8,9,10,11} print(number1.union(number2)) print(number1.difference(number2)) print(number1.isdisjoint(number2)) print(number1.isdisjoint(number3)) . {1, 2, 3, 4, 5, 6, 7, 8} {1, 2, 3} False True . Lists . empty_list = [] list_str=[&quot;Toyota&quot;,&quot;VW&quot;,&quot;BMW&quot;,&quot;Mercedes&quot;] list_bool=[True, False, False, True] list_str[1] . &#39;VW&#39; . print(list_str[len(list_str)-1]) print(list_str[-1]) . Mercedes Mercedes . list_str[0] = &quot;Hyundai&quot; list_str . [&#39;Hyundai&#39;, &#39;VW&#39;, &#39;BMW&#39;, &#39;Mercedes&#39;] . list_str += [&#39;Dacia&#39;, &#39;Ford&#39;] list_str . [&#39;Hyundai&#39;, &#39;VW&#39;, &#39;BMW&#39;, &#39;Mercedes&#39;, &#39;Dacia&#39;, &#39;Ford&#39;] . list_str.sort() list_str.reverse() list_str.pop() . &#39;BMW&#39; . new_list = list_str.copy() list_str.clear() list_str del list_str . list_2 = sorted(new_list) list_2 . [&#39;Dacia&#39;, &#39;Ford&#39;, &#39;Hyundai&#39;, &#39;Mercedes&#39;, &#39;VW&#39;] . print(new_list[0:2]) print(new_list[:-1]) . [&#39;VW&#39;, &#39;Mercedes&#39;] . &quot;Dacia&quot; in new_list . True . car_matrix = [[&quot;Hennessey Venom GT&quot;, 1244], [&quot;SSC Ultimate Aero&quot;, 1287], [&quot;Zenvo ST1&quot;, 1100]] car_matrix print(len(car_matrix)) print(len(car_matrix[1])) print(car_matrix[1][0]) . 3 2 SSC Ultimate Aero . Functions . Functions in general . country = &quot;USA&quot; def some_fn(): print(&quot;Country: &quot;, country) . some_fn() . Country: USA . def some_fn(): global country # interpret the global variable country = &quot;Bangladesh&quot; print(country) some_fn() print(country) # global variable has changed . Bangladesh Bangladesh . fruits_list = [&quot;Apple&quot;, &quot;Grapes&quot;, &quot;Mango&quot;, &quot;Bananas&quot;] def change_list(fruits_list): fruits_list[0] = &quot;Kiwi&quot; fruits_list = [&quot;Kiwi&quot;] # does nothing on the outside print(&quot;Inside the function: &quot;, fruits_list) change_list(fruits_list) print() print(&quot;Outside the function: &quot;, fruits_list) . Inside the function: [&#39;Kiwi&#39;] Outside the function: [&#39;Kiwi&#39;, &#39;Grapes&#39;, &#39;Mango&#39;, &#39;Bananas&#39;] . import math print(math.pi) . 3.141592653589793 . def calculate(*args, fn): # * -&gt; multiple arguments, unpack the args tuple return fn(*args) def diameter_circle_fn(r): pass calculate(10, fn=diameter_circle_fn) . def area_rectangle_fn(length, breadth): return length * breadth def calculate(*args, fn): # * -&gt; multiple arguments, unpack the args tuple return fn(*args) calculate(20, 40, fn=area_rectangle_fn) . 800 . Lambdas . def square(x): return x * x . result = square(5) . cube_of = lambda x: x * x * x result = cube_of(3) result . 27 . add = lambda x, y: x + y result = add(5, 10) result . 15 . (lambda x: x + 2)(10) . 12 . num_list = [1,5,6,7,11,78,99,34,105,214] filter(lambda x: x &gt; 10, num_list) . &lt;filter at 0x2220e96dd30&gt; . greater_than_10_list = list(filter(lambda x: x &gt; 10, num_list)) greater_than_10_list . [11, 78, 99, 34, 105, 214] . Functions advanced . Recursion . def hello(name): print(&quot;Hello&quot;, name) hello(name) #hello(&quot;Ron&quot;) - endless loop . import sys sys.getrecursionlimit() . 3000 . Generators . def generator(): print(&quot;One!&quot;) yield 1 # control execution flow print(&quot;Two!&quot;) yield 2 print(&quot;Three!&quot;) yield 3 g = generator() # no code execution g . &lt;generator object generator at 0x0000013378275970&gt; . next(g) . One! . 1 . def generate_even_numbers(limit): for i in range(0, limit, 2): yield i g = generate_even_numbers(7) next(g) . 0 . next(g) . 2 . Closures . def nested_hello_fn(): def hello(): print(&quot;Hello Cathy!&quot;) hello() nested_hello_fn() . Hello Cathy! . def get_hello_fn(): # every closure has its own local state (do not share local variables) def hello(): print(&quot;Hello Cathy!&quot;) return hello hello_fn = get_hello_fn() hello_fn() . Hello Cathy! . Decorators . import random def print_message(): print(&quot;Yohoo! Decorators are cool!&quot;) def make_highlighted(func): annotations = [&quot;-&quot;, &quot;*&quot;, &quot;+&quot;] annotate = random.choice(annotations) print(annotate * 50) func() print(annotate * 50) make_highlighted(print_message) @make_highlighted # that&#39;S how they are really used def print_a_message(): print(&quot;Now you&#39;ll see how decorators are used&quot;) print_a_message . -- Yohoo! Decorators are cool! -- -- Now you&#39;ll see how decorators are used -- . def plus_highlight(func): def highlight(): print(&quot;+&quot;*50) func() print(&quot;+&quot;*50) return highlight def asterisk_highlight(func): def highlight(): print(&quot;*&quot;*50) func() print(&quot;*&quot;*50) return highlight @plus_highlight @asterisk_highlight def hello(): print(&quot;hello!&quot;) hello() . ++++++++++++++++++++++++++++++++++++++++++++++++++ ************************************************** hello! ************************************************** ++++++++++++++++++++++++++++++++++++++++++++++++++ . Data Structures . Queues . from queue import Queue olympics = Queue(5) olympics . &lt;queue.Queue at 0x1934fae89d0&gt; . olympics.put(&quot;United Statues(USA)&quot;) olympics.put(&quot;Great Britain(GBR)&quot;) print(olympics.empty()) print(olympics.full()) print(olympics.qsize()) olympics.put(&quot;China(CHN)&quot;) olympics.put(&quot;Russia(RUS)&quot;) olympics.put(&quot;Germany(GER)&quot;) . False False 2 . print(olympics.full()) olympics.get() . True . &#39;United Statues(USA)&#39; . Stacks . stack = [] stack.append(&quot;United States&quot;) stack.append(&quot;Great Britain&quot;) stack.append(&quot;China&quot;) stack . [&#39;United States&#39;, &#39;Great Britain&#39;, &#39;China&#39;] . stack.pop() . &#39;China&#39; . Linked Lists . class Node: def __init__(self, dataval=None, nextval=None): self.dataval = dataval self.nextval = nextval def __repr__(self): return repr(self.dataval) class LinkedList: def __init__(self): self.head = None def __repr__(self): # O(N) nodes = [] curr = self.head while curr: nodes.append(repr(curr)) curr = curr.nextval return &quot;[&quot; + &quot;-&gt;&quot;.join(nodes) + &quot;]&quot; def prepend(self, dataval): # O(1) self.head = Node(dataval=dataval, nextval = self.head) def append(self, dataval): if not self.head: self.head = Node(dataval=dataval) return curr = self.head while curr.nextval: curr = curr.nextval curr.nextval = Node(dataval=dataval) def add_after(self, middle_dataval, dataval): if middle_dataval is None: print(&quot;Data to insert after not specified&quot;) return curr = self.head while curr and curr.dataval != middle_dataval: curr = curr.nextval new_node = Node(dataval = dataval) new_node.nextval = curr.nextval curr.nextval = new_node def find(self, data): curr = self.head while curr and curr.dataval != data: curr = curr.nextval return curr def remove(self, data): curr = self.head prev = None while curr and curr.dataval != data: prev = curr curr = curr.nextval if prev is None: self.head = curr.nextval elif curr: prev.nextval = curr.nextval curr.nextval = None def reverse(self): curr = self.head prev_node = None next_node = None while curr: nextval = curr.nextval curr.nextval = prev_node prev_node = curr curr = nextval self.head = prev_node . numbers = LinkedList() numbers.append(&quot;two&quot;) numbers.append(&quot;three&quot;) numbers.prepend(&quot;one&quot;) numbers . [&#39;one&#39;-&gt;&#39;two&#39;-&gt;&#39;three&#39;] . Classes and Inheritance . Basics . # special methods are marked with __methodname__ class Student: def __init__(self, name): # can be anything, but self is standard self.name = name # self refers to the current instance self.mail = name + &quot;.&quot; + &quot;@xyz.com&quot; . class Competition: # class variable raise_amount = 1.04 def __init__(self, name, prize): self.name = name self.prize = prize def raise_prize(self): self.prize = self.prize * Competition.raise_amount . debate = Competition(&#39;Debate&#39;, 500) print(debate.raise_amount) . 1.04 . Private attributes . # hack for private attributes: class Dog: def __init__(self, name, breed): self.__name = name self.__breed = breed def print_details(self): print(&#39;My name is %s and I am a %s&#39; % (self.__name, self.__breed)) d1 = Dog(&quot;Moje&quot;, &quot;Golden Retriever&quot;) d1.print_details() . My name is Moje and I am a Golden Retriever . d1.__name = &quot;Oba&quot; d1.print_details() # doesn&#39;t update . My name is Moje and I am a Golden Retriever . d1._Dog__breed = &quot;Husky&quot; # makes it harder to change, but can be changed d1.print_details() . My name is Moje and I am a Husky . Special Methods . class Competition: def __init__(self, name, country, prize): self.__name = name self.__country = country self.__prize = prize def get_name_country(self): return &#39;{} {}&#39;.format(self.__name, self.__country, self.__prize) def __repr__(self): # representation for print function return &quot;Competition: {} held in {}, prize: {}&quot;.format(self.__name, self.__country, self.__prize) def __str__(self): return &quot;&#39;{} - {}&#39;&quot;.format(self.get_name_country(), self.__prize) archery = Competition(&quot;Archery&quot;, &quot;Germany&quot;, 8000) repr(archery) . &#39;Competition: Archery held in Germany, prize: 8000&#39; . str(archery) # looks for special method __str__() . &#34;&#39;Archery Germany - 8000&#39;&#34; . int.__add__(1, 2) . 3 . Properties . class Wrestler: def __init__(self, name): self.__name = name @property # this is the method for accessing def name(self): print(&quot;getter method called&quot;) return self.__name @name.setter # this is the method for setting new vals def name(self, value): print(&quot;setter method called&quot;) self.__name = value @name.deleter def name(self): del self.__name w = Wrestler(&quot;Kart&quot;) . w.name . getter method called . &#39;Kart&#39; . Class Methods / Static Methods . class Competition: __raise_amount = 1.04 # class variable def __init__(self, name, country, prize): self.__name = name self.__country = country self.__prize = prize def raise_prize(self): self.__prize = self.__prize * self.__raise_amount def get_name_country(self): return &#39;{} {}&#39;.format(self.__name, self.__country, self.__prize) def __repr__(self): # representation for print function return &quot;Competition: {} held in {}, prize: {}&quot;.format(self.__name, self.__country, self.__prize) def __str__(self): return &quot;&#39;{} - {}&#39;&quot;.format(self.get_name_country(), self.__prize) @classmethod def get_raise_amount(cls): return cls.__raise_amount @classmethod def set_raise_amount(cls, amount): cls.__raise_amount = amount . c1 = Competition(&quot;Running&quot;, &quot;Germany&quot;, 50000) c1.set_raise_amount(2) c1.get_raise_amount() . 2 . Competition.get_raise_amount() . 2 . class Rectangle: @staticmethod # cannot access class variables def area(x,y): return x * y Rectangle.area(5,5) . 25 . Abstract Methods . from abc import ABC, abstractmethod class Hominidae(ABC): @abstractmethod # how to do it def diet(self): pass @abstractmethod def walk(self): pass def behavior(self): print(&quot;Blabla&quot;) . Inheritance . class Shape: def __init__(self, shape_type, color=&quot;Red&quot;): # optional self.__type = shape_type self.__color = color def get_type(self): return self.__type def get_color(self): return self.__color def get_area(self): pass def get_perimeter(self): pass class Circle(Shape): pass circle = Circle(&quot;circle&quot;) type(circle) . __main__.Circle . class Square(Shape): def __init__(self): Shape.__init__(self, &quot;square&quot;) square = Square() square.get_type() . &#39;square&#39; . issubclass(Circle, Shape) . True . class Father: def height(self): print(&quot;I have inherited my height from my father&quot;) class Mother: def intelligence(self): print(&quot;I have inherited my intelligence from my mother&quot;) class Child(Father, Mother): def experience(self): print(&quot;My experience are all my own&quot;) c = Child() c.height() . I have inherited my height from my father . c.intelligence() . I have inherited my intelligence from my mother . Creational Design Patterns . Singletons . a class of which only a single instance can exist | Ensure a class is instantiated only once, and provide a global point of access to it | . class Logger: __instance = None def __init__(self): raise RuntimeError(&#39;Call get_instance() instead&#39;) @classmethod def get_instance(cls): if cls.__instance is None : print(&#39;No instance exists, creating a new one&#39;) cls.__instance = cls.__new__(cls) else: print(&#39;A previously created instance exists, returning that same one&#39;) return cls.__instance logger1 = Logger.get_instance() logger1 . Pythonic implementation . new is always called first -&gt; it creates the instance | cls is reference to not yet existing instance | init is used to initialize the existing instance -&gt; self is a reference to the instance | . class PythonicLogger: __instance = None def __init__(self): print(&#39;Object initialized&#39;) # put your custom code here # is called every time - could be expensive def __new__(cls): if cls.__instance is None: print(&#39;No instance exists, creating a new one&#39;) cls.__instance = super(PythonicLogger, cls).__new__(cls) else: print(&#39;A previously created instance exists, returning that same one&#39;) return cls.__instance . class SuperLogger: __instance = None def __new__(cls): if cls.__instance is None: print(&#39;No instance exists, creating a new one&#39;) cls.__instance = super(SuperLogger, cls).__new__(cls) # Place all initialization code here else: print(&#39;A previously created instance exists, returning that same one&#39;) return cls.__instance . Factory &amp; Abstract Factory Design Patterns . Separate the creation of objects from their use | Class creation or Object creation | Class-creation patterns use inheritance | Object-creation patterns use delegation | Factory method is specified in base class, implemented in derived classes | Creates an instance of several derived classes | Define an interface for creating an object, but let subclasses decide which class to instantiate | Used to postpone instantiation - responsibility passes from base class to derived classes | Factory method -&gt; create an instance of any of many derived classes | Abstract F. pattern -&gt; create an instance of any one of many families of derived classes | Abstract Factory: create instances of several families of classes encapsulate platform dependencies | . class Product: def __init__(self, name, price): self.__name = name self.__price = price def get_price(self): return self.__price . class MacBookAir(Product): def __init__(self, memory, os): Product.__init__(self, &#39;MacBookAir&#39;, 1031) self.__memory = memory self.__os = os class AppleIPad(Product): def __init__(self, generation): Product.__init__(self, &#39;AppleIPad&#39;, 529) self.__generation = generation class AppleIWatch(Product): def __init__(self): Product.__init__(self, &#39;AppleIWatch&#39;, 264) . class ProductFactory: @staticmethod def create(item_name, *args): if item_name == &#39;MacBookAir&#39;: return MacBookAir(*args) elif item_name == &#39;AppleIPad&#39;: return AppleIPad(*args) elif item_name == &#39;AppleIWatch&#39;: return AppleIWatch(*args) air = ProductFactory.create(&#39;MacBookAir&#39;, &#39;16GB&#39;, &#39;Sierra&#39;) ipad = ProductFactory.create(&#39;AppleIPad&#39;, &#39;2nd&#39;) iwatch = ProductFactory.create(&#39;AppleIWatch&#39;) iwatch . &lt;__main__.AppleIWatch at 0x193517d2610&gt; . Abstract Factory . An abstract factory is a factory that returns factories. A normal factory can be used to create sets of related objects. An abstract factory returns factories. Thus, an abstract factory is used to return factories that can be used to create sets of related objects. . import abc class Toy(metaclass=abc.ABCMeta): @abc.abstractmethod def show(self): pass class Color(metaclass=abc.ABCMeta): @abc.abstractmethod def show_color(self): pass . class Car(Toy): def show(self): print(&quot;Remote controlled car&quot;) class ActionFigure(Toy): def show(self): print(&quot;Captain America action figure&quot;) class ConstructionToy(Toy): def show(self): print(&quot;Lego&quot;) class Red(Color): def show_color(self): print(&quot;red&quot;) class Green(Color): def show_color(self): print(&quot;green&quot;) class Blue(Color): def show_color(self): print(&quot;blue&quot;) car = Car() red = Red() red.show_color(), car.show() . red Remote controlled car . (None, None) . class AbstractFactory(metaclass=abc.ABCMeta): @abc.abstractmethod def get_color(self): pass @abc.abstractmethod def get_toy(self): pass . # create Factory classes extending AbstractFactory class ColorfulToysFactory(AbstractFactory): def get_toy(self, toy_type): if toy_type == None: return None if toy_type == &quot;car&quot;: return Car() elif toy_type == &quot;action figure&quot;: return ActionFigure() elif toy_type == &quot;construction toy&quot;: return ConstructionToy() return None def get_color(self, color_type): if color_type == None: return None if color_type == &quot;red&quot;: return Red() elif color_type == &quot;green&quot;: return Green() elif color_type == &quot;blue&quot;: return Blue() return None . # concrete classes by passing an information such as type RED_CAR = &#39;red_car&#39; BLUE_LEGO = &#39;blue_lego&#39; GREEN_ACTION_FIGURE = &#39;green_action_figure&#39; class ColorfulToysProducer: __colorful_toys_factory = ColorfulToysFactory() @classmethod def get_toy_and_color(cls, choice): toy = None color = None if choice == RED_CAR: toy = cls.__colorful_toys_factory.get_toy(&#39;car&#39;) color = cls.__colorful_toys_factory.get_color(&#39;red&#39;) elif choice == BLUE_LEGO: toy = cls.__colorful_toys_factory.get_toy(&#39;construction toy&#39;) color = cls.__colorful_toys_factory.get_color(&#39;blue&#39;) elif choice == GREEN_ACTION_FIGURE: toy = cls.__colorful_toys_factory.get_toy(&#39;action figure&#39;) color = cls.__colorful_toys_factory.get_color(&#39;green&#39;) return toy, color toy, color = ColorfulToysProducer.get_toy_and_color(RED_CAR) toy, color . (&lt;__main__.Car at 0x193517f9280&gt;, &lt;__main__.Red at 0x193517f9dc0&gt;) . toy, color = ColorfulToysProducer.get_toy_and_color(BLUE_LEGO) toy, color . (&lt;__main__.ConstructionToy at 0x1934fb85fd0&gt;, &lt;__main__.Blue at 0x1934fb855b0&gt;) . Builder Pattern . Builder Pattern . Separate the construction of an object from representation | allow same construction process for many representations | parse a complex representation, create different objects | Consider a SQL query builder class | allows step-by-step creation of a SQL query | Query is a complex entity with many different parts | Applications might build once, run multiple times | Separates object construction from its representation | parse a complex construction process into simple constituent operations | . class Mobile: def __init__(self, name, weight, screen_size, ram, os, camera_mp, battery): self.name = name self.weight = weight self.screen_size = screen_size self.ram = ram self.os = os self.camera_mp = camera_mp self.battery = battery def show(self): print(&quot;name:&quot;, self.name) print(&quot;weight:&quot;, self.weight) print(&quot;screen_size:&quot;, self.screen_size) print(&quot;ram:&quot;, self.ram) print(&quot;os:&quot;, self.os) print(&quot;camera_mp:&quot;, self.camera_mp) print(&quot;battery:&quot;, self.battery) . samsung_s10 = Mobile(name=&quot;Samsung S10&quot;, weight = &quot;157g&quot;, screen_size = &quot;6.1 inch&quot;, ram = &quot;8GB&quot;, os = &quot;android 9.0&quot;, camera_mp = &quot;12 megapixel&quot;, battery = &quot;3400 mAh&quot;) . samsung_s10.show() . name: Samsung S10 weight: 157g screen_size: 6.1 inch ram: 8GB os: android 9.0 camera_mp: 12 megapixel battery: 3400 mAh . to get rid of the long list of parameters we can have the features in the main program but directly setting attributes in the client program is wrong, it goes against &quot;encapsulate what varies principle&quot; | this is prone to errors and maintenance unfriendly | . class Mobile(): def __init__(self): self.name = None self.weight = None self.screen_size = None self.ram = None self.os = None self.camera_mp = None self.battery = None def show(self): print(&quot;name:&quot;, self.name) print(&quot;weight:&quot;, self.weight) print(&quot;screen_size:&quot;, self.screen_size) print(&quot;ram:&quot;, self.ram) print(&quot;os:&quot;, self.os) print(&quot;camera_mp:&quot;, self.camera_mp) print(&quot;battery:&quot;, self.battery) s10 = Mobile() s10.name = &quot;Samsung S10&quot; s10.screen_size = &quot;6.1 inch&quot;, s10.os = &quot;android 9.0&quot;, s10.camera_mp = &quot;12 megapixel&quot;, s10.battery = &quot;3400 mAh&quot; s10.show() . # the build method instantiates a new mobile object and encapsulates setting # of attributes class MyMobileBuilder(): def __init__(self): self.__mobile = Mobile() def get_mobile(self): return self.__mobile def build_name(self, name): self.__mobile.name = name def build_memory(self, ram): self.__mobile.ram = ram def build_camera(self, camera_mp): self.__mobile.camera_mp = camera_mp def build_otherfeatures(self, weight, screen_size, os, battery): self.__mobile.weight = weight self.__mobile.screen_size = screen_size self.__mobile.os = os self.__mobile.battery = battery builder = MyMobileBuilder() builder.build_name(&#39;Samsung S10&#39;) builder.build_memory(&#39;8GB&#39;) builder.build_camera(&#39;16 megapixels&#39;) mobile = builder.get_mobile() mobile.show() . name: Samsung S10 weight: None screen_size: None ram: 8GB os: None camera_mp: 16 megapixels battery: None . class Mobile: def __init__(self, name, weight=&#39;157gm&#39;, screen_size=&#39;5inches&#39;, ram=&#39;8GB&#39;, os=&#39;Android&#39;, camera_mp=&#39;16 megapixels&#39;, battery=&#39;3400 mAh&#39;): self.name = name self.weight = weight self.screen_size = screen_size self.ram = ram self.os = os self.camera_mp = camera_mp self.battery = battery def show(self): print(&quot;name:&quot;, self.name) print(&quot;weight:&quot;, self.weight) print(&quot;screen_size:&quot;, self.screen_size) print(&quot;ram:&quot;, self.ram) print(&quot;os:&quot;, self.os) print(&quot;camera_mp:&quot;, self.camera_mp) print(&quot;battery:&quot;, self.battery) samsung_s10 = Mobile(&#39;Samsung S10&#39;) samsung_s10.show() . name: Samsung S10 weight: 157gm screen_size: 5inches ram: 8GB os: Android camera_mp: 16 megapixels battery: 3400 mAh . samsung_s8 = Mobile(&#39;Samsung S8&#39;, screen_size=&#39;4.4inches&#39;, ram=&#39;4GB&#39;) samsung_s8.show() . name: Samsung S8 weight: 157gm screen_size: 4.4inches ram: 4GB os: Android camera_mp: 16 megapixels battery: 3400 mAh . Object Pool Pattern . Used when the cost of initializing objects is high | Number of objects in use at a time is low | Rate of object instantiation is high | Pools used to cache and manage objects | Avoid creating new objects, when an existing one is available | Reuse objects rather than incur the cost of creating one | common example: thread pools | some processes are embarrassingly parallel | threads are expensive to create and free up | use a thread pool -&gt; mitigates the overhead of pool creation | avoids needless re-instantiation and expensive acquisition of resources | . class Connection: def __init__(self): self.__is_used = False # Imagine a very heavy-duty initialization process here # to set up the database connections and connect self.connect_to_database() def acquire(self): self.__is_used = True def release(self): self.__is_used = False def is_used(self): return self.__is_used def connect_to_database(self): pass . class ConnectionPool: __instance = None def __new__(cls, num_connections): if cls.__instance is None: print(&#39;No instance exists, creating a new one&#39;) cls.__instance = super(ConnectionPool, cls).__new__(cls) cls.__instance.__num_connections = num_connections cls.__instance.__connections = [] for i in range(num_connections): cls.__instance.__connections.append(Connection()) else: print(&#39;A previously created instance exists, returning that same one&#39;) return cls.__instance def acquire(self): for i in range(self.__num_connections): connection = self.__connections[i] if not connection.is_used(): connection.acquire() return connection return None def release(self, connection): if connection.is_used(): connection.release() . pool = ConnectionPool(2) . No instance exists, creating a new one . pool = ConnectionPool(2) . A previously created instance exists, returning that same one . conn_1 = pool.acquire() conn_1 . &lt;__main__.Connection at 0x1935180dd30&gt; . conn_2 = pool.acquire() conn_2 . &lt;__main__.Connection at 0x1935180d820&gt; . conn_3 = pool.acquire() conn_3 is None . True . pool.release(conn_2) . conn_3 = pool.acquire() conn_3 . &lt;__main__.Connection at 0x1935180d820&gt; .",
            "url": "https://elydora.github.io/DataScienceBlog/python/2021/10/25/python-short-reference.html",
            "relUrl": "/python/2021/10/25/python-short-reference.html",
            "date": " • Oct 25, 2021"
        }
        
    
  
    
        ,"post2": {
            "title": "Where to open a Restaurant in LA County, CA?",
            "content": "Coursera Capstone Project . Finding a location and type for a restaurant in Los Angeles County, CA . . Introduction: Business Problem | Data | Methodology | Analysis | Results and Discussion | Conclusion | . Introduction: Business Problem . In this project I will try to give a recommendation on where to open a restaurant in Los Angeles County, CA. In addition, there shall be given a recommendation of which type of restaurant could be opened, based on existing restaurants in the area and generally popular restaurants in the whole county. . The decision on where to open a restaurant can be based on many factors, depending on the target group. For example, one could look for very dense populated areas, or areas with lots of wealthy citizens. Even the median age of the population can play a role. . I will make a decision based on the following conditions: . Find the area with a good balance between number of possible customers and a high median income (population is slightly more important than income) | the type of restaurant will be determined by the most recommended categories of food venue in Los Angeles County, CA and the number of already existing venues in the area | . Data . I used three different datasets as basis for my analysis. Using these datasets I am able to work with the following features, among others: . A list of areas in Los Angeles County, CA based on the ZIP code | The number of citizens and households in every area | The estimated median income of every area | The latitude and longitude for every zip code in the county | . . I combined the following datasets for this: . 2010 Los Angeles Census Data https://www.kaggle.com/cityofLA/los-angeles-census-data | . | Median Household Income by Zip Code in 2019 http://www.laalmanac.com/employment/em12c.php | . | US Zip Code Latitude and Longitude https://public.opendatasoft.com/explore/dataset/us-zip-code-latitude-and-longitude/information/ | . | . To analyse the existing food venues in the county, the Foursquare API is used. With this API we can provide the data to answer the following two questions: . What are the most recommended types of restaurants in the county? | What are the existing food venues categories in the area where we want to open a restaurant in? | . . Merging the three datasets as basis of the analytics . First, let&#39;s merge all three datasets and get rid of unnecessary information. I will continue to use a single dataframe with the combined datasets as basis for further analysis. . The census data and the geodata for the US zip codes are available as csv files that I will read directly into a dataframe. The records for the median household income are available on a website, so I downloaded the data as a html file, which then is used to create a dataframe. As the median income has a dollar sign and can not be converted into a numeric value automatically because of its format, we have to do some data preparation. . import pandas as pd from pathlib import Path census_path = Path.cwd().joinpath(&#39;resources&#39;).joinpath(&#39;2010-census-populations-by-zip-code.csv&#39;) html_path = Path.cwd().joinpath(&#39;resources&#39;).joinpath(&#39;Median Household Income By Zip Code in Los Angeles County, California.html&#39;) zip_path = Path.cwd().joinpath(&#39;resources&#39;).joinpath(&#39;us-zip-code-latitude-and-longitude.csv&#39;) # Dataset: 2010 Los Angeles Census Data df_census = pd.read_csv(census_path) # Dataset: Median Household Income by Zip Code in 2019 dfs = pd.read_html(html_path) df_income_all = dfs[0] # drop areas where the median income is missing df_income_na = df_income_all[df_income_all[&#39;Estimated Median Income&#39;].notna()] # Next step: clean the values in the median income column to retrieve # numeric values that can be used for clustering / calculation df_income = df_income_na.drop(df_income_na[df_income_na[ &#39;Estimated Median Income&#39;] == &#39;&#39;].index) df_income[&#39;Estimated Median Income&#39;] = df_income[&#39;Estimated Median Income&#39;].map(lambda x: x.lstrip(&#39;$&#39;)) df_income[&#39;Estimated Median Income&#39;] = df_income[&#39;Estimated Median Income&#39;].str.replace(&#39;,&#39;,&#39;&#39;) df_income[&quot;Estimated Median Income&quot;] = pd.to_numeric(df_income[&quot;Estimated Median Income&quot;]) # Dataset: US Zip Code Latitude and Longitude df_geodata = pd.read_csv(zip_path, sep=&#39;;&#39;) # Let&#39;s start by joining the geodata on the income dataset via the zip code df_income_geo = df_census.join(df_income.set_index(&#39;Zip Code&#39;), on=&#39;Zip Code&#39;) # Now join the census data with the income dataset and the geodata dataset_geo = df_income_geo.join(df_geodata.set_index(&#39;Zip&#39;), on=&#39;Zip Code&#39;, how=&#39;left&#39;) # Let us only use the columns we need for the further analysis and ignore # the rest prepared_ds = dataset_geo[[ &quot;Zip Code&quot;, &quot;City&quot;, &quot;Community&quot;, &quot;Estimated Median Income&quot;, &quot;Longitude&quot;, &quot;Latitude&quot;, &quot;Total Population&quot;, &quot;Median Age&quot;, &quot;Total Males&quot;, &quot;Total Females&quot;, &quot;Total Households&quot;, &quot;Average Household Size&quot;]] # last stop: let&#39;s drop records with missing data final_ds = prepared_ds.dropna(axis=0) final_ds.shape . (279, 12) . So the final dataframe now contains 279 areas with 12 features. Let&#39;s get an overview on how the records are looking: . final_ds.head(5) . Zip Code City Community Estimated Median Income Longitude Latitude Total Population Median Age Total Males Total Females Total Households Average Household Size . 1 90001 | Los Angeles | Los Angeles (South Los Angeles), Florence-Graham | 43360.0 | -118.24878 | 33.972914 | 57110 | 26.6 | 28468 | 28642 | 12971 | 4.40 | . 2 90002 | Los Angeles | Los Angeles (Southeast Los Angeles, Watts) | 37285.0 | -118.24845 | 33.948315 | 51223 | 25.5 | 24876 | 26347 | 11731 | 4.36 | . 3 90003 | Los Angeles | Los Angeles (South Los Angeles, Southeast Los ... | 40598.0 | -118.27600 | 33.962714 | 66266 | 26.3 | 32631 | 33635 | 15642 | 4.22 | . 4 90004 | Los Angeles | Los Angeles (Hancock Park, Rampart Village, Vi... | 49675.0 | -118.30755 | 34.077110 | 62180 | 34.8 | 31302 | 30878 | 22547 | 2.73 | . 5 90005 | Los Angeles | Los Angeles (Hancock Park, Koreatown, Wilshire... | 38491.0 | -118.30848 | 34.058911 | 37681 | 33.9 | 19299 | 18382 | 15044 | 2.50 | . Finding the most recommended food venue categories in the county . Now we will use the Foursquare API to find out what are the most recommended food venues in the county. For this we will go through every single area and get the recommended food venues in the vicinity of the area center. . from modules import foursquare import requests CLIENT_ID = foursquare.CLIENT_ID CLIENT_SECRET = foursquare.CLIENT_SECRET ACCESS_TOKEN = foursquare.ACCESS_TOKEN VERSION = &#39;20210514&#39; # Foursquare API version LIMIT = 100 . areas = final_ds.drop([&#39;Estimated Median Income&#39;, &#39;Total &#39; &#39;Population&#39;, &#39;Median Age&#39;, &#39;Total Males&#39;, &#39;Total Females&#39;, &#39;Total Households&#39;, &#39;Average Household Size&#39;], 1) areas.head() . &lt;ipython-input-52-c2d1ea4784be&gt;:2: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument &#39;labels&#39; will be keyword-only . Cluster Label Zip Code City Community Longitude Latitude . 1 2 | 90001 | Los Angeles | Los Angeles (South Los Angeles), Florence-Graham | -118.24878 | 33.972914 | . 2 2 | 90002 | Los Angeles | Los Angeles (Southeast Los Angeles, Watts) | -118.24845 | 33.948315 | . 3 2 | 90003 | Los Angeles | Los Angeles (South Los Angeles, Southeast Los ... | -118.27600 | 33.962714 | . 4 2 | 90004 | Los Angeles | Los Angeles (Hancock Park, Rampart Village, Vi... | -118.30755 | 34.077110 | . 5 2 | 90005 | Los Angeles | Los Angeles (Hancock Park, Koreatown, Wilshire... | -118.30848 | 34.058911 | . In the next code block, we will iterate through every area in the dataframe and get up to 50 recommendations per area. For that I use the &quot;explore&quot; endpoint of the Foursquare API. I use the categoryId and sortByPopularity parameters to only request food venues that are sorted by popularity in descending order. . venues_list = [] for index, area in areas.iterrows(): url = &#39;https://api.foursquare&#39; &#39;.com/v2/venues/explore?&amp;client_id={}&amp;client_secret={}&amp;v={}&amp;ll={},&#39; &#39;{}&amp;radius={}&amp;limit={}&amp;offset={}&amp;categoryId={}&amp;sortByPopularity={}&#39; .format( CLIENT_ID, CLIENT_SECRET, VERSION, area[&#39;Latitude&#39;], area[&#39;Longitude&#39;], 1000, LIMIT, 0, &#39;4d4b7105d754a06374d81259&#39;, 1) results = requests.get(url).json()[&quot;response&quot;][&#39;groups&#39;][0][&#39;items&#39;] for v in results: try: # try to extract the city, if there is one in the response city = v[&#39;venue&#39;][&#39;location&#39;][&#39;city&#39;] except: city = area[&#39;City&#39;] try: # try to extract the zip code, if there is one postalCode = str(v[&#39;venue&#39;][&#39;location&#39;][&#39;postalCode&#39;]) except: postalCode = str(area[&#39;Zip Code&#39;]) # build a list with all the columns I want to use if postalCode == str(area[&#39;Zip Code&#39;]): venues_list.append(( area[&#39;Zip Code&#39;], area[&#39;Community&#39;], area[&#39;Latitude&#39;], area[&#39;Longitude&#39;], v[&#39;venue&#39;][&#39;name&#39;], v[&#39;venue&#39;][&#39;categories&#39;][0][&#39;name&#39;], city )) # create a dataframe from the results of the request la_venues = pd.DataFrame(venues_list, columns=[&#39;Zip Code&#39;, &#39;Community&#39;, &#39;Zip Code Latitude&#39;, &#39;Zip Code Longitude&#39;, &#39;Venue&#39;, &#39;Venue Category&#39;, &#39;City&#39;]) . la_venues.head() . Zip Code Community Zip Code Latitude Zip Code Longitude Venue Venue Category City . 0 90001 | Los Angeles (South Los Angeles), Florence-Graham | 33.972914 | -118.24878 | Mi Lindo Nayarit Mariscos | Mexican Restaurant | Los Angeles | . 1 90001 | Los Angeles (South Los Angeles), Florence-Graham | 33.972914 | -118.24878 | Jack in the Box | Fast Food Restaurant | Los Angeles | . 2 90001 | Los Angeles (South Los Angeles), Florence-Graham | 33.972914 | -118.24878 | Mi Lindo Nayarit | Seafood Restaurant | Los Angeles | . 3 90001 | Los Angeles (South Los Angeles), Florence-Graham | 33.972914 | -118.24878 | SUBWAY | Sandwich Place | Los Angeles | . 4 90001 | Los Angeles (South Los Angeles), Florence-Graham | 33.972914 | -118.24878 | El Senor Taco | Mexican Restaurant | Los Angeles | . la_venues[&quot;Venue&quot;].count() . 8692 . So we have found 8,692 recommendations for our 279 areas in Los Angeles County, CA. That are ~31 recommendations per area. Let&#39;s extract the city and venue category and group the data by category, to find out about the distribution of the recommended food venue categories. . venues = la_venues[[&#39;City&#39;, &#39;Venue Category&#39;]] categories = venues.groupby(&#39;Venue Category&#39;).size().to_frame(&#39;Count&#39;).reset_index() sorted = categories.sort_values(by=&#39;Count&#39;, ascending=False) # Sort by Count top10 = sorted.iloc[0:9] # Show the top 10 categories top10 . Venue Category Count . 76 Mexican Restaurant | 833 | . 88 Pizza Place | 575 | . 40 Fast Food Restaurant | 501 | . 22 Chinese Restaurant | 417 | . 8 Bakery | 347 | . 98 Sandwich Place | 342 | . 1 American Restaurant | 316 | . 17 Café | 304 | . 13 Burger Joint | 264 | . After that, we will visualize the distribution. . import plotly.express as px from IPython.display import HTML, display top15 = sorted.iloc[0:14] fig = px.bar(top15, x=&quot;Venue Category&quot;, y=&quot;Count&quot;, title=&#39;Distribution of recommended food venue categories&#39;) HTML(fig.to_html(include_plotlyjs=&#39;cdn&#39;)) #fig.show(renderer=&#39;notebook_connected&#39;) . . . So with this data we can tell what food venue categories are recommended the most throughout Los Angeles County, CA. . We have prepared the following data, which we will use for further analysis: . a dataframe with areas in LA County, enriched with geodata, median income and census data | a dataframe with the most recommended food venue categories in the county | . Methodology . In this project we will focus on finding a suitable area for a new restaurant in Los Angeles County, CA. The areas are defined by their US Zip Code. In addition, we will look at the most recommended food venue categories throughout the country, to suggest which type of restaurant could be opened. There won&#39;t be a specific location in the chosen area recommended. . In the first step we have merged three different datasets, that provide data on the different areas in Los Angeles County. With this data it is possible to cluster the areas using information like median income, number of households and number of inhabitants. In addition, using Foursquare, we identified the most recommended food venue categories in the county. . The second step in the analysis is to cluster (using k-means clustering) the areas in the county and to describe the individual clusters. Using this method we support the process of finding a single area that looks promising for a new restaurant. . The third step is to pick a cluster that fits the chosen criteria most. The area shall be chosen under the premise of finding a good balance between estimated median income and number of potential customers. So the target is to find an area that has as many citizens as possible with the highest income possible. After an area was chosen, the distribution of local restaurant types in this area will be analysed. Combining this information with the categories of food venues that are popular throughout the county, a recommendation of the restaurant to open can be given. . Analysis . Getting an overview . First of all, let&#39;s have a look on our dataset describing the areas. . final_ds.head() . Zip Code City Community Estimated Median Income Longitude Latitude Total Population Median Age Total Males Total Females Total Households Average Household Size . 1 90001 | Los Angeles | Los Angeles (South Los Angeles), Florence-Graham | 43360.0 | -118.24878 | 33.972914 | 57110 | 26.6 | 28468 | 28642 | 12971 | 4.40 | . 2 90002 | Los Angeles | Los Angeles (Southeast Los Angeles, Watts) | 37285.0 | -118.24845 | 33.948315 | 51223 | 25.5 | 24876 | 26347 | 11731 | 4.36 | . 3 90003 | Los Angeles | Los Angeles (South Los Angeles, Southeast Los ... | 40598.0 | -118.27600 | 33.962714 | 66266 | 26.3 | 32631 | 33635 | 15642 | 4.22 | . 4 90004 | Los Angeles | Los Angeles (Hancock Park, Rampart Village, Vi... | 49675.0 | -118.30755 | 34.077110 | 62180 | 34.8 | 31302 | 30878 | 22547 | 2.73 | . 5 90005 | Los Angeles | Los Angeles (Hancock Park, Koreatown, Wilshire... | 38491.0 | -118.30848 | 34.058911 | 37681 | 33.9 | 19299 | 18382 | 15044 | 2.50 | . Now we are going to take a look at the areas with the highest income and the highest population. . income_sorted = final_ds.sort_values(by=&#39;Estimated Median Income&#39;, ascending=False) income_top15 = income_sorted.iloc[0:14] fig = px.bar(income_top15, x=&quot;Estimated Median Income&quot;, y=&quot;City&quot;, orientation = &quot;h&quot;, color=&#39;Estimated Median Income&#39;, title=&#39;Distribution of Estimated Median Income&#39;) HTML(fig.to_html(include_plotlyjs=&#39;cdn&#39;)) #fig.show(renderer=&#39;notebook_connected&#39;) . . . pop_sorted = final_ds.sort_values(by=&#39;Total Population&#39;, ascending=False) pop_top15 = pop_sorted.iloc[0:14] fig = px.bar(pop_top15, y=&quot;Total Population&quot;, x=&quot;City&quot;, orientation = &quot;v&quot;, color=&#39;Total Population&#39;, title=&#39;Distribution of Population&#39;) HTML(fig.to_html(include_plotlyjs=&#39;cdn&#39;)) #fig.show(renderer=&#39;notebook_connected&#39;) . . . As we are primarily interested in the areas that have a high total population, let us add the income to this graph and get an overview on which areas in this group have the highest income. . fig = px.scatter(pop_top15, x=&quot;Estimated Median Income&quot;, y=&quot;Community&quot;, size=&quot;Total Population&quot;, log_x=True, color=&quot;Total Population&quot;) HTML(fig.to_html(include_plotlyjs=&#39;cdn&#39;)) #fig.show(renderer=&#39;notebook_connected&#39;) . . . In this graph the population determines the bubble size. So there are four areas that stand out: . City Population Median Income . Norwalk | 105,6K | 70,7K | . Lake View Terrace, Sylmar | 91,7K | 74K | . La Puente, Valinda | 85K | 71,2K | . Hansen Hills, Pacoima | 104K | 64K | . These four cities / neighbourhoods seem to be suitable areas, based on their combination of population and median income. We are going to see, if this assumption is confirmed going forward. . Clustering the dataset . from sklearn.cluster import KMeans grouped_clustering = final_ds.drop([&#39;Zip Code&#39;, &#39;City&#39;, &#39;Community&#39;, &#39;Longitude&#39;, &#39;Latitude&#39;, &#39;Total Males&#39;, &#39;Total Females&#39;], 1) grouped_clustering.head() . &lt;ipython-input-15-dc927ff3f295&gt;:2: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument &#39;labels&#39; will be keyword-only . Estimated Median Income Total Population Median Age Total Households Average Household Size . 1 43360.0 | 57110 | 26.6 | 12971 | 4.40 | . 2 37285.0 | 51223 | 25.5 | 11731 | 4.36 | . 3 40598.0 | 66266 | 26.3 | 15642 | 4.22 | . 4 49675.0 | 62180 | 34.8 | 22547 | 2.73 | . 5 38491.0 | 37681 | 33.9 | 15044 | 2.50 | . sum_of_squared_distances = [] K = range(1,15) for k in K: kmeans = KMeans(n_clusters=k, init=&quot;k-means++&quot;, random_state=0).fit(grouped_clustering) sum_of_squared_distances.append(kmeans.inertia_) #kmeans.labels_ . C: Users schul miniconda3 lib site-packages sklearn cluster _kmeans.py:881: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2. . import matplotlib.pyplot as plt plt.plot(K, sum_of_squared_distances, &#39;bx-&#39;) plt.xlabel(&#39;k&#39;) plt.ylabel(&#39;Sum_of_squared_distances&#39;) plt.title(&#39;Elbow Method For Optimal k&#39;) plt.show() . According to the elbow method I chose a k of 6 going forward. So let&#39;s do the clustering again with the determined k value. Then I will add the cluster labels to my dataset and print out a summarization of the created clusters. . kmeans = KMeans(n_clusters=6, init=&quot;k-means++&quot;, random_state=0).fit(grouped_clustering) # add the labels to the dataset final_ds.insert(0, &#39;Cluster Label&#39;, kmeans.labels_) . cluster_df = final_ds.groupby(&#39;Cluster Label&#39;).mean() cluster_df . Zip Code Estimated Median Income Longitude Latitude Total Population Median Age Total Males Total Females Total Households Average Household Size . Cluster Label . 0 90944.044444 | 51793.866667 | -118.206034 | 34.081385 | 18356.955556 | 35.786667 | 9296.088889 | 9060.866667 | 6044.355556 | 2.850444 | . 1 90624.000000 | 155063.444444 | -118.425995 | 34.024770 | 17967.666667 | 43.838889 | 8777.833333 | 9189.833333 | 7020.722222 | 2.479444 | . 2 90645.573770 | 52440.918033 | -118.253427 | 34.038718 | 49920.491803 | 32.331148 | 24696.983607 | 25223.508197 | 15608.819672 | 3.248852 | . 3 91028.756410 | 79091.974359 | -118.215469 | 34.065151 | 29618.141026 | 38.174359 | 14394.820513 | 15223.320513 | 10698.910256 | 2.776026 | . 4 90971.672727 | 105903.872727 | -118.327527 | 34.099429 | 29382.745455 | 41.198182 | 14361.127273 | 15021.618182 | 11328.072727 | 2.540727 | . 5 91153.090909 | 57912.863636 | -118.190515 | 34.113848 | 83146.500000 | 30.468182 | 41257.500000 | 41889.000000 | 22069.545455 | 3.768182 | . Let us clean this up a bit and add a new column, that will help us to chose a cluster going forward. . clusters = cluster_df[[&#39;Estimated Median Income&#39;, &#39;Total Population&#39;, &#39;Median Age&#39;, &#39;Total Households&#39;, &#39;Average Household &#39; &#39;Size&#39;]] clusters[&#39;Decision Factor&#39;] = ( ( clusters[&#39;Total Population&#39;] * 1.2 ) * clusters[&#39;Estimated Median Income&#39;]) / 100000 clusters_r = clusters.round(2) clusters_r clusters_sorted = clusters_r.sort_values(by=&#39;Decision Factor&#39;, ascending=False) clusters_sorted . &lt;ipython-input-20-ab34df8160b4&gt;:5: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame. Try using .loc[row_indexer,col_indexer] = value instead See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy . Estimated Median Income Total Population Median Age Total Households Average Household Size Decision Factor . Cluster Label . 5 57912.86 | 83146.50 | 30.47 | 22069.55 | 3.77 | 57783.02 | . 4 105903.87 | 29382.75 | 41.20 | 11328.07 | 2.54 | 37340.96 | . 1 155063.44 | 17967.67 | 43.84 | 7020.72 | 2.48 | 33433.54 | . 2 52440.92 | 49920.49 | 32.33 | 15608.82 | 3.25 | 31414.52 | . 3 79091.97 | 29618.14 | 38.17 | 10698.91 | 2.78 | 28110.69 | . 0 51793.87 | 18356.96 | 35.79 | 6044.36 | 2.85 | 11409.33 | . Looking at these clusters, they can be described as the following: . Name Income Population Age . Cluster 4 | High | Medium | Older | . Cluster 0 | Low | Low | Young | . Cluster 1 | Very High | Low | Older | . Cluster 5 | Medium | Very High | Very Young | . Cluster 2 | Low | High | Very Young | . Cluster 3 | High | Medium | Young | . So based on this information I am going to choose Cluster 5 for further evaluation and as the cluster where I will pick an area from. This cluster has a medium income combined with a very high population. It also contains the youngest median age, which also can be considered for choosing the food venue category. . cluster5 = final_ds.loc[final_ds[&#39;Cluster Label&#39;] == 5, final_ds .columns[[1] + list(range(2, final_ds.shape[1]))]] cluster5.shape . (22, 12) . This cluster contains 22 areas in Los Angeles County, CA. We are going to have a look on them on the map using Folium. . from geopy.geocoders import Nominatim # initialize the map address = &#39;Los Angeles County, CA&#39; geolocator = Nominatim(user_agent=&quot;la_explorer&quot;) location = geolocator.geocode(address) latitude = location.latitude longitude = location.longitude . import matplotlib.cm as cm import matplotlib.colors as colors import folium import numpy as np # create map map_clusters = folium.Map(location=[latitude, longitude], zoom_start=11) cluster5 = final_ds.loc[final_ds[&#39;Cluster Label&#39;] == 5] # set color scheme for the clusters, 6 is our number of clusters x = np.arange(6) ys = [i + x + (i*x)**2 for i in range(6)] colors_array = cm.rainbow(np.linspace(0, 1, len(ys))) rainbow = [colors.rgb2hex(i) for i in colors_array] # add markers to the map markers_colors = [] for lat, lon, poi, cluster in zip(cluster5[&#39;Latitude&#39;], cluster5[&#39;Longitude&#39;], cluster5[&#39;Zip Code&#39;], cluster5[&#39;Cluster Label&#39;]): label = folium.Popup(str(poi) + &#39; Cluster &#39; + str(cluster), parse_html=True) folium.CircleMarker( [lat, lon], radius=5, popup=label, color=rainbow[cluster], fill=True, fill_color=rainbow[cluster], fill_opacity=0.7).add_to(map_clusters) #map_clusters . from IPython.display import Image from pathlib import Path path = Path.cwd().joinpath(&#39;png&#39;).joinpath(&#39;2021-06-24-capstone.png&#39;) Image(filename=path) . As one can see, most of our areas in more densely populated areas and in the vicinity of the city of Los Angeles. Now let us add the &quot;decision factor&quot; again and calculate it for every single region in cluster 5. . cluster5[&#39;Decision Factor&#39;] = ( ( cluster5[&#39;Total Population&#39;] * 1.2 ) * cluster5[&#39;Estimated Median Income&#39;]) / 100000 cluster5_r = cluster5.round(2) cluster5_sorted = cluster5_r.sort_values(by=&#39;Decision Factor&#39;, ascending=False) cluster5_sorted.head(10) . &lt;ipython-input-45-58ad054c4b50&gt;:1: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame. Try using .loc[row_indexer,col_indexer] = value instead See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy . Cluster Label Zip Code City Community Estimated Median Income Longitude Latitude Total Population Median Age Total Males Total Females Total Households Average Household Size Decision Factor . 132 5 | 90650 | Norwalk | Norwalk | 70667.0 | -118.08 | 33.91 | 105549 | 32.5 | 52364 | 53185 | 27130 | 3.83 | 89505.97 | . 214 5 | 91342 | Sylmar | Los Angeles (Lake View Terrace, Sylmar), Kagel... | 74050.0 | -118.43 | 34.31 | 91725 | 31.9 | 45786 | 45939 | 23543 | 3.83 | 81506.84 | . 211 5 | 91331 | Pacoima | Los Angeles (Arleta, Hansen Hills, Pacoima) | 63807.0 | -118.42 | 34.25 | 103689 | 29.5 | 52358 | 51331 | 22465 | 4.60 | 79393.01 | . 266 5 | 91744 | La Puente | City of Industry, La Puente, Valinda | 71243.0 | -117.94 | 34.03 | 85040 | 30.9 | 42564 | 42476 | 18648 | 4.55 | 72702.06 | . 309 5 | 93536 | Lancaster | Del Sur, Fairmont, Lancaster, Metler Valley, N... | 79990.0 | -118.33 | 34.73 | 70918 | 34.4 | 37804 | 33114 | 20964 | 3.07 | 68072.77 | . 129 5 | 90631 | La Habra | La Habra Heights | 83629.0 | -117.95 | 33.93 | 67619 | 34.8 | 33320 | 34299 | 21452 | 3.13 | 67858.91 | . 85 5 | 90250 | Hawthorne | Hawthorne (Holly Park) | 56304.0 | -118.35 | 33.91 | 93193 | 31.9 | 45113 | 48080 | 31087 | 2.98 | 62965.66 | . 254 5 | 91706 | Baldwin Park | Baldwin Park, Irwindale | 65755.0 | -117.97 | 34.09 | 76571 | 30.5 | 37969 | 38602 | 17504 | 4.35 | 60419.11 | . 99 5 | 90280 | South Gate | South Gate | 52321.0 | -118.19 | 33.94 | 94396 | 29.4 | 46321 | 48075 | 23278 | 4.05 | 59266.72 | . 158 5 | 90805 | Long Beach | Long Beach (North Long Beach) | 50914.0 | -118.18 | 33.87 | 93524 | 29.0 | 45229 | 48295 | 26056 | 3.56 | 57140.17 | . cluster5_top5 = cluster5_sorted.iloc[0:5] fig = px.bar(cluster5_top5, x=&#39;Decision Factor&#39;, y=&#39;Community&#39;, color=&#39;Average Household Size&#39; ) HTML(fig.to_html(include_plotlyjs=&#39;cdn&#39;)) #fig.show(renderer=&#39;notebook_connected&#39;) . . . So there are three areas that stand out: . Norwalk, with a population of 105,6k and an income of $70,6k; it has the oldest median age of the three communities and the largest population. | Lake View Terrace in Sylmar, with a population of 91,7k and an income of $74k; it has the highest income of the group and the lowest population. | Hansen Hills in Pacoima, with a population 104,7k and an income of $63,8k. It has the youngest median age of the three and is very close to Norwalk in terms of population, but it has the lowest income. | . Looking back at the initial analysis we did for all areas in Los Angeles County, we find that these three areas were also part auf the group we found, based on their features. So through the clustering we could confirm our initial findings. . Exploring local food venues . Using Foursquare, we are going to query the existing food venues in the three areas. . We will use a radius of 4 kilometres around the center of every community. I will also use the city and zip code from the response to filter out results from Foursquare that actually do not belong to the city community we are exploring. . import itertools top3 = cluster5_sorted.iloc[0:3] venues_list=[] # Get the local food venues for all 3 of our communities for _, record in top3.iterrows(): offset = 0 for _ in itertools.repeat(None, 4): url = &#39;https://api.foursquare&#39; &#39;.com/v2/venues/explore?&amp;client_id={}&amp;client_secret={}&amp;v={}&amp;ll={},&#39; &#39;{}&amp;radius={}&amp;limit={}&amp;offset={}&amp;categoryId={}&#39;.format( CLIENT_ID, CLIENT_SECRET, VERSION, record[&#39;Latitude&#39;], record[&#39;Longitude&#39;], 4000, 50, offset, &#39;4d4b7105d754a06374d81259&#39;) # increase the offset for the next run offset += 50 # try to read the items from the Foursquare response and loop over them try: results = requests.get(url).json()[&quot;response&quot;][&#39;groups&#39;][0][&#39;items&#39;] for v in results: # get the city name from the Foursquare response, if possible try: city = v[&#39;venue&#39;][&#39;location&#39;][&#39;city&#39;] except: city = str(record[&#39;City&#39;]) # get the zip code from the Foursquare response, if possible try: postalCode = str(v[&#39;venue&#39;][&#39;location&#39;][&#39;postalCode&#39;]) except: postalCode = str(record[&#39;Zip Code&#39;]) venues_list.append((record[&#39;Zip Code&#39;], record[&#39;Community&#39;], record[&#39;Latitude&#39;], record[&#39;Longitude&#39;], v[&#39;venue&#39;][&#39;name&#39;], v[&#39;venue&#39;][&#39;categories&#39;][0][&#39;name&#39;], city, postalCode)) except: # there are no more results that Foursquare can deliver break # create a dataframe from all venues we have found for all 3 areas nearby_venues = pd.DataFrame(venues_list, columns=[&#39;Zip Code&#39;, &#39;Community&#39;, &#39;Zip Code Latitude&#39;, &#39;Zip Code Longitude&#39;, &#39;Venue&#39;, &#39;Venue Category&#39;, &#39;City&#39;, &#39;PostalCode&#39;]) nearby_venues.count() . Zip Code 364 Community 364 Zip Code Latitude 364 Zip Code Longitude 364 Venue 364 Venue Category 364 City 364 PostalCode 364 dtype: int64 . venues_cleaned = nearby_venues.loc[ nearby_venues[&#39;City&#39;].isin([&#39;Norwalk&#39;, &#39;Sylmar&#39;, &#39;Pacoima&#39;])] venues_cleaned.count() . Zip Code 160 Community 160 Zip Code Latitude 160 Zip Code Longitude 160 Venue 160 Venue Category 160 City 160 PostalCode 160 dtype: int64 . We found 160 food venues across all 3 areas. In the next step we will group the food venues by category and city. We can use the count of food venues per category to visualize the distribution across the communities. . categs = venues_cleaned[[&#39;City&#39;, &#39;Venue Category&#39;]] # count the number of restaurants per city and category categs_count = categs.groupby([&#39;City&#39;, &#39;Venue Category&#39;]).size().to_frame( &#39;Count&#39;).reset_index() # sort the result by city and count categs_sorted = categs_count.sort_values(by=[&#39;City&#39;, &#39;Count&#39;], ascending=False) categs_sorted . City Venue Category Count . 44 Sylmar | Mexican Restaurant | 12 | . 45 Sylmar | Pizza Place | 7 | . 47 Sylmar | Sandwich Place | 6 | . 38 Sylmar | Chinese Restaurant | 5 | . 35 Sylmar | American Restaurant | 3 | . 43 Sylmar | Fried Chicken Joint | 3 | . 39 Sylmar | Donut Shop | 2 | . 40 Sylmar | Fast Food Restaurant | 2 | . 41 Sylmar | Food | 2 | . 36 Sylmar | Asian Restaurant | 1 | . 37 Sylmar | Breakfast Spot | 1 | . 42 Sylmar | Food Court | 1 | . 46 Sylmar | Restaurant | 1 | . 48 Sylmar | Seafood Restaurant | 1 | . 49 Sylmar | Snack Place | 1 | . 50 Sylmar | Sushi Restaurant | 1 | . 51 Sylmar | Taco Place | 1 | . 52 Sylmar | Thai Restaurant | 1 | . 28 Pacoima | Mexican Restaurant | 9 | . 25 Pacoima | Fast Food Restaurant | 7 | . 31 Pacoima | Sandwich Place | 3 | . 32 Pacoima | Taco Place | 3 | . 23 Pacoima | Burger Joint | 2 | . 30 Pacoima | Pizza Place | 2 | . 20 Pacoima | American Restaurant | 1 | . 21 Pacoima | BBQ Joint | 1 | . 22 Pacoima | Breakfast Spot | 1 | . 24 Pacoima | Chinese Restaurant | 1 | . 26 Pacoima | Food Court | 1 | . 27 Pacoima | Fried Chicken Joint | 1 | . 29 Pacoima | Middle Eastern Restaurant | 1 | . 33 Pacoima | Thai Restaurant | 1 | . 34 Pacoima | Wings Joint | 1 | . 7 Norwalk | Fast Food Restaurant | 15 | . 13 Norwalk | Mexican Restaurant | 12 | . 15 Norwalk | Sandwich Place | 8 | . 14 Norwalk | Pizza Place | 7 | . 5 Norwalk | Chinese Restaurant | 5 | . 6 Norwalk | Donut Shop | 5 | . 0 Norwalk | American Restaurant | 4 | . 1 Norwalk | Asian Restaurant | 3 | . 4 Norwalk | Burger Joint | 3 | . 11 Norwalk | Fried Chicken Joint | 2 | . 2 Norwalk | Bakery | 1 | . 3 Norwalk | Breakfast Spot | 1 | . 8 Norwalk | Food | 1 | . 9 Norwalk | Food Court | 1 | . 10 Norwalk | Food Truck | 1 | . 12 Norwalk | Korean Restaurant | 1 | . 16 Norwalk | Steakhouse | 1 | . 17 Norwalk | Sushi Restaurant | 1 | . 18 Norwalk | Taco Place | 1 | . 19 Norwalk | Thai Restaurant | 1 | . categs_graph = categs_sorted.loc[categs_sorted[&#39;Count&#39;] &gt; 1] fig = px.bar(categs_graph, y=&quot;Venue Category&quot;, x=&quot;Count&quot;, title=&#39;Combined Distribution of Food Venues&#39;, orientation=&#39;h&#39;, color = &#39;City&#39; ) HTML(fig.to_html(include_plotlyjs=&#39;cdn&#39;)) #fig.show(renderer=&#39;notebook_connected&#39;) . . . Having a look at the distribution of food venues across the three areas, we can make the following observations: . Mexican restaurants are the most common food venue overall | Fast Food restaurants are the second most common venue, but Norwalk has by far the most | Pacoima has the least restaurants overall and Norwalk the most, despite both of them are very close in population | There seems to be space for a Chinese or American Restaurant or a Donut Shop in Pacoima | Even sandwich and pizza places are not very common in Pacoima | Opening another fast food restaurant or mexican restaurant does not seem like a good idea | . Again, let us have a look on the most recommended food venues in the county for comparison: . top15 = sorted.iloc[0:14] fig = px.bar(top15, x=&quot;Venue Category&quot;, y=&quot;Count&quot;, title=&#39;Distribution of recommended food venue categories&#39;) #fig.show(renderer=&#39;notebook_connected&#39;) HTML(fig.to_html(include_plotlyjs=&#39;cdn&#39;)) . . . Choosing a restaurant to open . Bakeries are the fith most recommended venue category, but there is currently a maximum of 1 per area. So this could be a good option in any of the three communities. | Mexican and fast food restaurants are already very common and should not be chosen | There is an opportunity for a pizza place or a chinese resaturant in Pacoima | Pacoima in general has few food venues. Looking at the median income, any low price food venues could be a good opportunity. | Norwalk would be the best option according to population and income, but it is already very crowded with restaurants. A bakery seems to be the best option there. | . There are also multiple options for sushi restaurants, burger joints, japanese or thai restaurants in all three areas. Overall not looking bad! . Results and Discussion . Our analysis shows that there is a high variability in population, income and median age in the different areas of Los Angeles County, CA. So it was possible to identify multiple areas that fit the criteria of a relatively high median income and a high population. Using census and income data of all areas in Los Angeles County, we did a clustering to identify similar areas. By analysing the formed clusters there have been three areas identified that fit the criteria best. Norwalk, Lake View Terrace in Sylmar and Hansen Hills in Pacoima. . They are slightly different in income, population and age and also very different in their local distribution of available food venues. The final area could be picked on which of these factors matters to the stakeholders most. I will pick Norwalk as the final area for a food venue, because it offers the best combination of a high population and a good income out of these three areas. . By analysing the most recommended food venue categories across the whole county, we found that mexican restaurants are by far the most often recommended venue. After them pizza places, fast food restaurants, chinese restaurants and bakeries follow in that order. To give a recommendation for a food venue to open in Norwalk, we can compare the local distribution of food venues what was recommended the most in the county. By looking at Norwalk we found that there are already many mexican restaurants (12) and fast food restaurants (15). Pizza places (7) and chinese restaurants (5) area also recommended in a higher number, so opening a restaurant in one of those categories would be better, but there is still some competition. What stands out is that there is currently only one bakery recommended by Foursquare in Norwalk. Looking at the distribution of recommendations in the county, bakeries are the fifth most recommended venue category. Because of this, I would recommend opening a bakery in Norwalk, CA to the stakeholders. . Purpose of this analysis was to identify a possible area and food venue type for a new restaurant in Los Angeles County, CA based on a very limited amount of factors. Analysing census data and existing food venues is only one part on the way to find a location for opening a new restaurant. Other factors that also play a role are for example available spaces, rent costs, other venues in the area. This analysis serves as a starting point for finding possible locations, but further analysis needs to be done by the stakeholders. . Conclusion . The purpose of this project was to find a possible location for a new restaurant in Los Angeles County, CA. The desire from the stakeholders was to identify locations that offer a good balance between median income and number of inhabitants, although income shall be rated slightly more important than population. In addition, the idea was to identify possible food venue categories by comparing recommended venues across the country with the local venues in the different areas. So for this there were census and income data combined to identify areas that fit the criteria. A clustering was performed, to group the communities in Los Angeles County using their income and population. Then the cluster was chosen that fit the former mentioned criteria the most. From this cluster the top 3 areas were chosen, that had the best balance between income and population. This way the best three candidates for a new restaurant location were identified. . The next step was to analyze the local food venue categories. For this the local venues in a 4 km radius were identified and grouped. This grouping was then compared with the distribution of the most recommended food venue categories across the whole county. In doing so, opportunities for new restaurants in any of the three chosen communities have been identified. . The final decision can be made by the stakeholders, based on the recommendations given in this project. This decision for a locality can be based on income, population or median age of the areas. The decision for a venue category can be based on popular venues across the county, and the gaps in the local food offerings that have been identified. .",
            "url": "https://elydora.github.io/DataScienceBlog/ibm/data_science/ml/visualization/2021/06/24/capstone-project.html",
            "relUrl": "/ibm/data_science/ml/visualization/2021/06/24/capstone-project.html",
            "date": " • Jun 24, 2021"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "SAP developer by day, Python developer by night. . This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://elydora.github.io/DataScienceBlog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://elydora.github.io/DataScienceBlog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}